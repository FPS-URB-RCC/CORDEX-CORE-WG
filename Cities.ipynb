{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b96eab-8aba-4a09-a90b-ec33e6a1fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import glob\n",
    "from skimage.morphology import dilation, square\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import cartopy.feature as cfeature\n",
    "from itertools import product\n",
    "import sys\n",
    "import cftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57080220-4cb6-4c21-8893-09acfbcbaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/'\n",
    "dest = '/lustre/gmeteo/WORK/diezsj/research/cordex-fps-urb-rcc/results/'\n",
    "ucdb_info = gpd.read_file(root  + 'CORDEX-CORE-WG/GHS_FUA_UCD/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_2.gpkg')\n",
    "\n",
    "rcms = {\n",
    "  'AFR-22' : [\n",
    "    'REMO2015',\n",
    "    'RegCM4-7',\n",
    "  ],\n",
    "  'AUS-22' : [\n",
    "    'REMO2015',\n",
    "    'RegCM4-7',\n",
    "  ],\n",
    "  'CAM-22' : [\n",
    "    'REMO2015',\n",
    "    'RegCM4-7',\n",
    "  ],\n",
    "  'SAM-22' : [\n",
    "    'REMO2015',\n",
    "    'RegCM4-7',\n",
    "  ],\n",
    "  'WAS-22' : [\n",
    "    'REMO2015',\n",
    "    'RegCM4-7',\n",
    "  ],\n",
    "  'EUR-11': [\n",
    "    'REMO2015',\n",
    "    'RegCM4-6',\n",
    "  ],\n",
    "  'EAS-22': [\n",
    "#    'RegCM4-0', # No opendap access\n",
    "    'REMO2015'\n",
    "  ],\n",
    "  'SEA-22' : [\n",
    "    'REMO2015',\n",
    "    'RegCM4-7',\n",
    "  ],\n",
    "  'NAM-22': [\n",
    "    'RegCM4_v4-4-rc8',\n",
    "    'REMO2015',\n",
    "  ]\n",
    "}\n",
    "\n",
    "# coordinates name\n",
    "rlat_names = {'rlat', 'y' }\n",
    "rlon_names = {'rlon', 'x'}\n",
    "\n",
    "rotated_pole_names = {'rotated_pole', 'rotated_latitude_longitude', 'Lambert_Conformal',\n",
    "                     'oblique_mercator', 'crs'}\n",
    "\n",
    "# Dictionary containing city locations and their respective domains\n",
    "location = {\n",
    "     'Mexico City' : dict(lon=-99.0833, lat=19.4667, domain = 'CAM-22'),\n",
    "     'Buenos Aires' : dict(lon=-58.416, lat=-34.559, domain = 'SAM-22'),\n",
    "     'New York' : dict(lon=-74.2261, lat=40.8858, domain = 'NAM-22'),\n",
    "     'Sydney' : dict(lon=151.01810, lat=-33.79170, domain = 'AUS-22'),\n",
    "     'Beijing' : dict(lon=116.41, lat=39.90, domain = 'EAS-22'),\n",
    "     'Tokyo' : dict(lon = 139.84, lat = 35.65, domain = 'EAS-22'),\n",
    "     'Jakarta' : dict(lon = 106.81, lat = -6.2, domain = 'SEA-22'), \n",
    "     'Johannesburg' : dict(lon=28.183, lat=-25.733, domain = 'AFR-22'),\n",
    "     'Riyadh' : dict(lon=46.73300, lat=24.7000, domain = 'WAS-22'),\n",
    "     'Berlin' : dict(lon=13.4039, lat=52.4683, domain = 'EUR-11'),\n",
    "     'Paris' : dict(lon=  2.35, lat=48.85, domain = 'EUR-11'),\n",
    "     'London' : dict(lon= -0.13, lat=51.50, domain = 'EUR-11'),\n",
    "     'Madrid' : dict(lon= -3.70, lat=40.42, domain = 'EUR-11'),\n",
    "     'Los Angeles': dict(lon = -118.24, lat = 34.05, domain = 'NAM-22'),\n",
    "     'Montreal': dict(lon = -73.56, lat = 45.50, domain = 'NAM-22'),\n",
    "     'Chicago': dict(lon = -87.55, lat = 41.73, domain = 'NAM-22'),\n",
    "     'Bogota': dict(lon = -74.06, lat = 4.62, domain = 'SAM-22'),\n",
    "     'Baghdad': dict(lon = 44.40, lat = 33.34, domain = 'WAS-22'),\n",
    "     'Tehran': dict(lon = 51.42, lat = 35.69, domain = 'WAS-22'),\n",
    "     'Tashkent': dict(lon = 69.24, lat = 41.31, domain = 'WAS-22'),\n",
    "     'Cairo': dict(lon = 31.25, lat = 30.06, domain = 'AFR-22'),\n",
    "     'Delhi [New Delhi]': dict(lon = 77.22, lat = 28.64, domain = 'WAS-22'),\n",
    "    'Barcelona': dict(lon = 2.18, lat = 41.39, domain = 'EUR-11'),\n",
    "    'Rome': dict(lon =  12.51, lat = 41.89, domain = 'EUR-11'),\n",
    "    'Athens': dict(lon =   23.72, lat =  37.98, domain = 'EUR-11'),\n",
    "\n",
    "}\n",
    "\n",
    "model_dict={\n",
    "     'REMO' : dict(urban_variable='urban',orog_variable='orog',sea_variable='sftlf'),\n",
    "    'RegCM' : dict(urban_variable='sftuf',orog_variable='orog',sea_variable='sftlf'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580b765-407b-46b8-857a-470b9ec2048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_city(city: str, location: dict, model: str, model_dict:dict, data: str = \"CORDEX-CORE\"):\n",
    "    '''\n",
    "    Retrieves urban, orography, sea masks, and temp dataset for the chosen city and model.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The chosen city.\n",
    "        location (dict): Dictionary containing city locations and their respective domains.\n",
    "        model (str): The chosen model. Options are \"REMO\" and \"RegCM\".\n",
    "        data (str): The chosen data options: CORDEX-CORE or CORDEX-EUR-11.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Dataset of minimal temperature, sea mask, orography mask, urban fraction, latitude, longitude of the city, and nearby stations.\n",
    "    '''\n",
    "    # Retrieve city data from location dictionary\n",
    "    city_data = location.get(city, {})\n",
    "    lon = city_data.get('lon')\n",
    "    lat = city_data.get('lat')\n",
    "    domain = city_data.get('domain')\n",
    "\n",
    "    if data==\"CORDEX-CORE\":\n",
    "        ds=xr.open_dataset(\"/lustre/gmeteo/WORK/DATA/C3S-CDS/C3S-CICA-Atlas/v1/CORDEX-CORE/historical/tn_CORDEX-CORE_historical_mon_197001-200512.nc\")\n",
    "    elif domain==\"EUR-11\" and data==\"CORDEX-EUR-11\":\n",
    "        ds=xr.open_dataset(\"/lustre/gmeteo/WORK/DATA/C3S-CDS/C3S-CICA-Atlas/v1/CORDEX-EUR-11/historical/tn_CORDEX-EUR-11_historical_mon_197001-200512.nc\")\n",
    "\n",
    "    # Paths for sea, orography, and urban masks based on model and domain\n",
    "    if model==\"REMO\":\n",
    "        base_path_sea='/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/REMO/land-sea-mask_C/'\n",
    "        base_path_urban='/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/REMO/urbanfraction_C/orig_v3/'\n",
    "        base_path_orography='/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/REMO/orography_C/'\n",
    "        # Searching for files\n",
    "        file_sea = glob.glob(base_path_sea +'*'+domain+'*')\n",
    "        file_urban = glob.glob(base_path_urban +'*'+domain+'*')\n",
    "        file_orography = glob.glob(base_path_orography+'*'+domain+'*')\n",
    "\n",
    "    elif model==\"RegCM\":\n",
    "        base_path_sea='/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/RegCM/land-sea-mask_C/'\n",
    "        base_path_urban='/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/RegCM/urbanfraction_C/'\n",
    "        base_path_orography='/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/RegCM/orography_C/'\n",
    "        # Searching for files\n",
    "        file_sea = glob.glob(base_path_sea +'*'+domain+'*')\n",
    "        file_urban = glob.glob(base_path_urban +'*'+domain+'*')\n",
    "        file_orography = glob.glob(base_path_orography+ '*'+domain+'*')\n",
    "\n",
    "\n",
    "    # Open datasets for sea, orography, and urban masks\n",
    "    sea_mask = xr.open_dataset(file_sea[0])\n",
    "    orography = xr.open_dataset(file_orography[0])\n",
    "    urbanfraction = xr.open_dataset(file_urban[0])\n",
    "\n",
    "    # Define variable names from model dictionary\n",
    "    urban_variable = model_dict.get(model, {}).get('urban_variable')\n",
    "    orog_variable = model_dict.get(model, {}).get('orog_variable')\n",
    "    sea_variable = model_dict.get(model, {}).get('sea_variable')\n",
    "                 \n",
    "    ds_urban = urbanfraction[urban_variable]\n",
    "    ds_orog = orography[orog_variable]\n",
    "    ds_sftlf = sea_mask[sea_variable]  \n",
    "\n",
    "    res = int(orography.attrs['CORDEX_domain'].split('-')[1])\n",
    "    \n",
    "    ghcnd_stations_url = 'https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/doc/ghcnd-stations.txt'\n",
    "    ghcnd_stations_column_names = ['code', 'lat', 'lon', 'elev', 'name', 'net', 'numcode']\n",
    "    ghcnd_stations_column_widths = [   11,     9,    10,      7,     34,     4,       10 ]\n",
    "    df = pd.read_fwf(ghcnd_stations_url, header = 0, widths = ghcnd_stations_column_widths, names = ghcnd_stations_column_names)\n",
    "    ghcnd_stations=gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat), crs = 'EPSG:4326')\n",
    "    \n",
    "    rval = ghcnd_stations.assign(dist = ghcnd_stations.distance(Point(lon, lat)))\n",
    "    rval.sort_values(by = 'dist', inplace = True)\n",
    "    rval = rval[rval.dist < 0.5].to_crs(epsg=3857)  \n",
    "    return ds, ds_sftlf, ds_orog, ds_urban, lat, lon, rval,res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffdccc-f418-4267-b959-3e253e082177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_name(names, avail_names):\n",
    "  # Select variable/coordinate names among a list of potential names.\n",
    "  # Potential names are matched against those available in the data set.\n",
    "  return(list(names.intersection(list(avail_names)))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf878cf8-6699-4bfa-afa3-ed0a6238984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(ax, lon, lat, dist_lon, dist_lat,color='blue',zorder=1,linewidth=1):\n",
    "    \"\"\"\n",
    "    Plot the boundary of a square defined by longitude and latitude values.\n",
    "\n",
    "    Parameters:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib axes to plot on.\n",
    "        lon (float): Longitude value.\n",
    "        lat (float): Latitude value.\n",
    "        dist_lon (float): Distance in longitude.\n",
    "        dist_lat (float): Distance in latitude.\n",
    "        color (str, optional): Color of the boundary line.\n",
    "    \"\"\"\n",
    "    ax.plot([lon - dist_lon, lon + dist_lon, lon + dist_lon, lon - dist_lon, lon - dist_lon],\n",
    "            [lat - dist_lat, lat - dist_lat, lat + dist_lat, lat + dist_lat, lat - dist_lat],\n",
    "            color=color, linewidth=linewidth,zorder=zorder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df79fb-9f0e-4b1b-aa5f-80582199a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_non_urban_cells(urban_mask,orog_mask,sftlf_mask,urban_surrounding_mask,scale=4):\n",
    "    \"\"\"\n",
    "    Selects non-urban cells surrounding urban areas based on dilation operation.\n",
    "\n",
    "    Parameters:\n",
    "        urban_mask (numpy.ndarray): Binary mask indicating urban areas.\n",
    "        orog_mask (numpy.ndarray): Binary mask indicating orography.\n",
    "        sftlf_mask (numpy.ndarray): Binary mask indicating sea areas.\n",
    "        scale (int): Scaling factor to determine the extent of non-urban area selection.\n",
    "\n",
    "    Returns:[~np.isnan(data_array)]\n",
    "        numpy.ndarray: Mask of selected non-urban cells.\n",
    "    \"\"\"\n",
    "    data_array = xr.DataArray(urban_surrounding_mask)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                       [1, 1, 1],\n",
    "                       [0, 1, 0]])\n",
    "    \n",
    "    urban_cells = np.sum(urban_mask)\n",
    "    non_urban_cells = 0\n",
    "    n_i = 0\n",
    "    while non_urban_cells <= urban_cells * scale:\n",
    "        \n",
    "        # Perform dilation\n",
    "        dilated_data = xr.apply_ufunc(dilation, \n",
    "                                      data_array if non_urban_cells == 0 else dilated_data, \n",
    "                                      kwargs={'footprint': kernel})\n",
    "        #Delete other fixed variables (to include)\n",
    "        #dilated_data = dilated_data.where(orog_mask & sftlf_mask)\n",
    "        dilated_data = (dilated_data * orog_mask * sftlf_mask).astype(int)\n",
    "        non_urban_cells = np.sum(dilated_data) - urban_cells\n",
    "        if n_i > 10:\n",
    "            print(\"Warning...\")\n",
    "            break\n",
    "        n_i = n_i + 1\n",
    "    \n",
    "    non_urban_mask = xr.DataArray(dilated_data.where(~urban_surrounding_mask).fillna(0))\n",
    "    return non_urban_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afb2a2-775a-4491-9d82-8ed8618d57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_urban_areas(ds_urban,ds_orog,ds_sftlf,urban_mask,non_urban_mask,orog_mask, sftlf_mask,urban_th, urban_elevation,orog_diff,sftlf_th,urban_area,scale):\n",
    "    # Definir una paleta de colores personalizada similar a \"terrain\" sin azules\n",
    "    colors = ['#7C5B49', '#92716B', '#A89080', '#C0B49E', '#DACCB9', '#F5F5DC']\n",
    "    # Crear la paleta de colores personalizada\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"custom_terrain\", colors)\n",
    "    \n",
    "    dset = orography.copy()\n",
    "    lonlat = ccrs.PlateCarree()\n",
    "    projvar = select_name(rotated_pole_names, dset.data_vars)\n",
    "    if projvar.startswith('rotated'):\n",
    "        proj = ccrs.RotatedPole(\n",
    "        pole_longitude=dset[projvar].grid_north_pole_longitude,\n",
    "        pole_latitude=dset[projvar].grid_north_pole_latitude\n",
    "        )\n",
    "    elif projvar.startswith('oblique'):\n",
    "        # To be implemented soon... (https://github.com/SciTools/cartopy/pull/2096)\n",
    "        proj = ccrs.ObliqueMercator(\n",
    "        pole_longitude=dset[projvar].grid_north_pole_longitude,\n",
    "        pole_latitude=dset[projvar].grid_north_pole_latitude\n",
    "        )\n",
    "    else:\n",
    "        proj = ccrs.LambertConformal(\n",
    "        central_longitude=dset[projvar].longitude_of_central_meridian,\n",
    "        central_latitude=dset[projvar].latitude_of_projection_origin,\n",
    "        standard_parallels=dset[projvar].standard_parallel\n",
    "        )\n",
    "\n",
    "                   \n",
    "    fig, axes = plt.subplots(2, 3, subplot_kw={'projection': proj}, figsize=(20, 10))\n",
    "    \n",
    "\n",
    "    urban_plot = ds_urban.\\\n",
    "                 plot(ax=axes[0, 0], cmap='binary', \n",
    "                 vmin = np.nanmin(ds_urban), vmax = np.nanmax(ds_urban))\n",
    "    axes[0, 0].set_title('Urban Fraction')\n",
    "    axes[0, 0].coastlines()\n",
    "    \n",
    "    orography_plot = ds_orog.plot(\n",
    "        ax=axes[0, 1], cmap=custom_cmap, \n",
    "        vmin = np.nanmin(ds_orog), vmax = np.nanmax(ds_orog)\n",
    "    )\n",
    "    axes[0, 1].set_title('Orography')\n",
    "    axes[0, 1].coastlines()\n",
    "    \n",
    "    sea_plot = ds_sftlf.plot(\n",
    "        ax=axes[0, 2], cmap='winter',\n",
    "        vmin = np.nanmin(ds_sftlf), vmax = np.nanmax(ds_sftlf))\n",
    "    axes[0, 2].set_title('sftlf')\n",
    "    axes[0, 2].coastlines()\n",
    "    \n",
    "    # masked data\n",
    "    urban_plot = ds_urban.where(urban_mask == 1, np.nan).plot(\n",
    "        ax=axes[1, 0], cmap='binary', \n",
    "        vmin = np.nanmin(ds_urban), vmax = np.nanmax(ds_urban))\n",
    "    axes[1, 0].set_title('Urban Fraction (mask >' +  str(urban_th) + ', scale = ' + str(scale) +  ')')\n",
    "    axes[1, 0].coastlines()\n",
    "    \n",
    "    orography_plot = ds_orog.where(orog_mask == 1, np.nan).plot(\n",
    "        ax=axes[1, 1], cmap=custom_cmap,\n",
    "        vmin = np.nanmin(ds_orog), vmax = np.nanmax(ds_orog))\n",
    "    axes[1, 1].set_title('orog (' + str(int(urban_elevation) - orog_diff) + \n",
    "                         ' m < mask > ' +  \n",
    "                         str(int(urban_elevation) + orog_diff) + ' m)'\n",
    "    )\n",
    "    axes[1, 1].coastlines()\n",
    "    \n",
    "    sea_mask_plot = ds_sftlf.where(sftlf_mask == 1, np.nan).plot(\n",
    "        ax=axes[1, 2], cmap='winter',\n",
    "        vmin = np.nanmin(ds_sftlf), vmax = np.nanmax(ds_sftlf)\n",
    "    )\n",
    "    axes[1, 2].set_title('sftlf (mask >' + str(sftlf_th) + '%)')\n",
    "    axes[1, 2].coastlines()\n",
    "    \n",
    "    \n",
    "    rlon_values = orog_mask[select_name(rlon_names, orog_mask.coords)].values\n",
    "    rlat_values = orog_mask[select_name(rlat_names, orog_mask.coords)].values\n",
    "    dist_rlon = (rlon_values[0]- rlon_values[1])/2\n",
    "    dist_rlat = (rlat_values[0]- rlat_values[1])/2 \n",
    "    \n",
    "    # Plot the border for cells for the differents masks\n",
    "    for k in range(3):\n",
    "        for i, j in product(range(np.shape(urban_mask)[0]), \n",
    "                            range(np.shape(urban_mask)[1])):\n",
    "\n",
    "            if urban_area['urban_area'].values[i, j] == 1:\n",
    "                plot_boundary(axes[1, k], rlon_values[j], rlat_values[i], \n",
    "                              dist_rlon, dist_rlat,'red',zorder=50)\n",
    "                                \n",
    "            elif urban_area['urban_area'].values[i, j] == 0:\n",
    "                plot_boundary(axes[1, k], rlon_values[j], rlat_values[i], \n",
    "                              dist_rlon, dist_rlat,'blue',zorder=5)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)  # Ajusta el espacio horizontal y vertical\n",
    "\n",
    "    plt.savefig('urban_areas.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2c90f-6de5-41ef-834e-0f0131ebcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cities(ds: xr.Dataset, city: str, model: str, model_dict:dict, ds_sftlf: xr.Dataset, ds_orog: xr.Dataset, ds_urban: xr.Dataset,\n",
    "                CORDEX: str, lat: int, lon: int, lon_lim: int, lat_lim: int, vtmin: int, vtmax: int, rval: xr.Dataset, rlat_names:xr,rlon_names: xr, rotated_pole_names:xr, res:int,\n",
    "                season: str='all',period: slice = slice('1980-01-01', '2000-12-31'),save_results:bool= True, urban_th: float = 0.1, urban_surrounding_th: float=0.1, scale:int= 4,\n",
    "                orog_diff: float = 100, sftlf_th:float=70,percentil: float =10) :\n",
    "    '''\n",
    "    Plots urban, orography, sea masks, and mean min temperature for selected cities and models.\n",
    "    \n",
    "    Parameters:\n",
    "    ds (xr.Dataset): Dataset containing temperature data.\n",
    "    city (str): The chosen city.\n",
    "    model (str): The chosen model.\n",
    "    ds_sftlf (xr.Dataset): Dataset containing sea mask data.\n",
    "    ds_orog (xr.Dataset): Dataset containing orography data.\n",
    "    ds_urban (xr.Dataset): Dataset containing urban fraction data.\n",
    "    CORDEX (str): Name of the CORDEX dataset.\n",
    "    lat (int): Latitude of the city.\n",
    "    lon (int): Longitude of the city.\n",
    "    dist_lon (int): Distance in longitude.\n",
    "    dist_lat (int): Distance in latitude.\n",
    "    vtmin (int): Minimum value for temperature.\n",
    "    vtmax (int): Maximum value for temperature.\n",
    "    season (str, optional): The selected season for filtering temperature data. \n",
    "                            Options are \"all\" (default), \"jfm\" (January-February-March), \"amj\" (April-May-June), \"jas\" (July-August-September), and \"ond\" (October-November-December).\n",
    "    period (slice): Slice object with datetime indices.\n",
    "    rval (xr.Dataset): Dataset containing values for reference.\n",
    "    orog_diff (int, optional): Maximum limit for orography. Defaults to 100.\n",
    "    sftlf_th.....\n",
    "    urban_th (float, optional): Minimum threshold for urban areas. Defaults to 0.1.\n",
    "    percentil (float, optional): Percentile value for calculating percentiles. Defaults to 10.\n",
    "    \n",
    "    Returns:\n",
    "    fig (plt.Figure): Plot object\n",
    "    '''\n",
    "\n",
    "    #Draws the city\n",
    "    root = '/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/'\n",
    "    ucdb_info = gpd.read_file(root  + 'CORDEX-CORE-WG/GHS_FUA_UCD/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_2.gpkg')\n",
    "    ucdb_city = ucdb_info.query(f'UC_NM_MN ==\"{city}\"').to_crs(crs = 'EPSG:4326')\n",
    "    if city == 'London':\n",
    "        ucdb_city = ucdb_city[ucdb_city['CTR_MN_NM'] == 'United Kingdom']\n",
    "    \n",
    "    # Select data from the dataset based on the time range and season\n",
    "    #ds = ds.sel(time=period)\n",
    "    season_to_month_bounds = {\n",
    "        'jfm': (1, 3),\n",
    "        'amj': (4, 6),\n",
    "        'jas': (7, 9),\n",
    "        'ond': (10, 12)\n",
    "    }\n",
    "    # Select data from dataset based on time range and season \n",
    "    if season != 'all':\n",
    "        lower_bound, upper_bound = season_to_month_bounds[season]\n",
    "        ds= ds.sel(time=(ds['time'].dt.month >= lower_bound) & (ds['time'].dt.month <= upper_bound))\n",
    "        ds= ds.sel(time=period)\n",
    "    #else:\n",
    "    #    ds= ds.sel(time=period)\n",
    "\n",
    "    # Define latitude and longitude ranges based on city location and distances\n",
    "    lon_min = lon - lon_lim\n",
    "    if lon_min <0:  \n",
    "        lon_min+=360\n",
    "    lon_max = lon + lon_lim\n",
    "    if lon_max <0:  \n",
    "        lon_max+=360\n",
    "    lat_min = lat - lat_lim\n",
    "    lat_max = lat + lat_lim\n",
    "\n",
    "    # Crop area around the city\n",
    "    dlon = int(111*lon_lim/res)\n",
    "    dlat = int(111*lat_lim/res)\n",
    "                    \n",
    "    # Create subplots with projection\n",
    "    dset = orography.copy()\n",
    "    lonlat = ccrs.PlateCarree()\n",
    "    projvar = select_name(rotated_pole_names, dset.data_vars)\n",
    "    if projvar.startswith('rotated'):\n",
    "        proj = ccrs.RotatedPole(\n",
    "        pole_longitude=dset[projvar].grid_north_pole_longitude,\n",
    "        pole_latitude=dset[projvar].grid_north_pole_latitude\n",
    "        )\n",
    "    elif projvar.startswith('oblique'):\n",
    "        # To be implemented soon... (https://github.com/SciTools/cartopy/pull/2096)\n",
    "        proj = ccrs.ObliqueMercator(\n",
    "        pole_longitude=dset[projvar].grid_north_pole_longitude,\n",
    "        pole_latitude=dset[projvar].grid_north_pole_latitude\n",
    "        )\n",
    "    else:\n",
    "        proj = ccrs.LambertConformal(\n",
    "        central_longitude=dset[projvar].longitude_of_central_meridian,\n",
    "        central_latitude=dset[projvar].latitude_of_projection_origin,\n",
    "        standard_parallels=dset[projvar].standard_parallel\n",
    "        )\n",
    "    fig, axes = plt.subplots(subplot_kw={'projection': proj}, figsize=(10, 10))\n",
    "    fig2, axes2 = plt.subplots(figsize=(20, 15))\n",
    "    \n",
    "\n",
    "    #Urban plot\n",
    "    #latitude_mask = (ds_urban.lat >= lat_min) & (ds_urban.lat <= lat_max)\n",
    "    #longitude_mask = (ds_urban.lon >= lon_min) & (ds_urban.lon <= lon_max)   \n",
    "    #Plot the contour of urban data        \n",
    "    #urban = ds_urban.where(latitude_mask & longitude_mask, drop=True)\n",
    "\n",
    "    if model==\"REMO\":\n",
    "        ds_urban['lon'][:] = ds_orog['lon']\n",
    "        ds_urban['lat'][:] = ds_orog['lat']\n",
    "    elif model==\"RegCM\":\n",
    "        ds_urban = ds_urban.assign_coords(x=ds_orog.x, y=ds_orog.y)\n",
    "\n",
    "                    \n",
    "    # Urban and non-urban mask\n",
    "    dist = (ds_urban['lon']-lon)**2 + (ds_urban['lat']-lat)**2\n",
    "    [ilat], [ilon] = np.where(dist == np.min(dist))\n",
    "    ds_urban = ds_urban.isel(**{\n",
    "    select_name(rlat_names, ds_urban.coords): slice(ilat-dlat,ilat+dlat),\n",
    "    select_name(rlon_names, ds_urban.coords): slice(ilon-dlon,ilon+dlon)\n",
    "    })      \n",
    "    urban_mask = ds_urban > urban_th\n",
    "    urban_surrounding_mask = ds_urban > urban_surrounding_th\n",
    "    if 'time' in urban_mask.dims:\n",
    "        urban_mask = urban_mask.isel(time=0)\n",
    "        urban_surrounding_mask = urban_surrounding_mask.isel(time=0)\n",
    "    \n",
    "    #lon_values = urban['lon'].values\n",
    "    #lat_values = urban['lat'].values\n",
    "    #dist_lon=(lon_values[0]- lon_values[1])/2\n",
    "    #dist_lat=(lat_values[0]- lat_values[1])/2            \n",
    "\n",
    "    # Orography mask\n",
    "    urban_elevation = ds_orog.where(urban_mask).mean().item()\n",
    "    dist = (ds_orog['lon']-lon)**2 + (ds_orog['lat']-lat)**2\n",
    "    [ilat], [ilon] = np.where(dist == np.min(dist))\n",
    "    ds_orog = ds_orog.isel(**{\n",
    "    select_name(rlat_names, ds_orog.coords): slice(ilat-dlat,ilat+dlat),\n",
    "    select_name(rlon_names, ds_orog.coords): slice(ilon-dlon,ilon+dlon)\n",
    "    })    \n",
    "    #urban_elevation = ds_orog.where(urban_mask).mean().item()\n",
    "    urban_elevation_max = ds_orog.where(urban_mask).max().item()\n",
    "    urban_elevation_min = ds_orog.where(urban_mask).min().item()\n",
    "    \n",
    "    orog_mask1 = ds_orog < (orog_diff + urban_elevation_max)\n",
    "    orog_mask2 = ds_orog > (urban_elevation_min - orog_diff)\n",
    "    orog_mask = orog_mask1 & orog_mask2\n",
    "\n",
    "    rlon_values = ds_orog[select_name(rlon_names, ds_orog.coords)].values\n",
    "    rlat_values = ds_orog[select_name(rlat_names, ds_orog.coords)].values\n",
    "    dist_rlon=(rlon_values[0]- rlon_values[1])/2\n",
    "    dist_rlat=(rlat_values[0]- rlat_values[1])/2 \n",
    "\n",
    "    # sftlf mask\n",
    "    dist = (ds_sftlf['lon']-lon)**2 + (ds_sftlf['lat']-lat)**2\n",
    "    [ilat], [ilon] = np.where(dist == np.min(dist))\n",
    "    ds_sftlf = ds_sftlf.isel(**{\n",
    "    select_name(rlat_names, ds_sftlf.coords): slice(ilat-dlat,ilat+dlat),\n",
    "    select_name(rlon_names, ds_sftlf.coords): slice(ilon-dlon,ilon+dlon)\n",
    "    })\n",
    "    sftlf_mask = ds_sftlf > sftlf_th   \n",
    "\n",
    "    non_urban_mask=select_non_urban_cells(urban_mask,orog_mask,sftlf_mask,urban_surrounding_mask,scale)\n",
    "    if save_results == True: \n",
    "        # Convert to dataset and create attribtes\n",
    "        urban_area = urban_mask.astype(int).where(urban_mask.astype(int) == 1, np.nan)\n",
    "        urban_area = urban_area.where(non_urban_mask.astype(int) == 0, 0)\n",
    "        urban_area = urban_area.to_dataset(name='urban_area')\n",
    "        \n",
    "        urban_area['urban_area'].attrs['long_name'] = 'Urban vs. vicinity. 1 corresponds to urban areas and 0 to the surrounding areas'\n",
    "        urban_area['urban_area'].attrs['lon_city'] = lon\n",
    "        urban_area['urban_area'].attrs['lat_city'] = lat\n",
    "        urban_area['urban_area'].attrs['urban_th'] = urban_th\n",
    "        urban_area['urban_area'].attrs['urban_surrounding_th'] = urban_surrounding_th\n",
    "        urban_area['urban_area'].attrs['orog_diff'] = orog_diff\n",
    "        urban_area['urban_area'].attrs['landsea_th'] = sftlf_th\n",
    "        urban_area['urban_area'].attrs['scale'] = scale\n",
    "        urban_area['urban_area'].attrs['lon_lim'] = lon_lim\n",
    "        urban_area['urban_area'].attrs['lat_lim'] = lat_lim\n",
    "    \n",
    "        urban_area.to_netcdf('urban_area.nc')\n",
    "        plot_urban_areas(ds_urban,ds_orog,ds_sftlf,urban_mask,non_urban_mask,orog_mask, sftlf_mask,urban_th,urban_elevation,orog_diff,sftlf_th,urban_area, scale)\n",
    "\n",
    "    # Plot contrast between urban areas \n",
    "    tn_mean=ds['tasmin'].isel(**{\n",
    "    select_name(rlat_names, ds_sftlf.coords): slice(ilat-dlat,ilat+dlat),\n",
    "    select_name(rlon_names, ds_sftlf.coords): slice(ilon-dlon,ilon+dlon)\n",
    "    }).where(urban_mask).mean().compute()\n",
    "    change=ds['tasmin'].isel(**{\n",
    "    select_name(rlat_names, ds_sftlf.coords): slice(ilat-dlat,ilat+dlat),\n",
    "    select_name(rlon_names, ds_sftlf.coords): slice(ilon-dlon,ilon+dlon)\n",
    "    }).mean(dim=['time'])-tn_mean\n",
    "    change.plot(ax=axes, transform=proj, cmap='seismic', vmin=vtmin,vmax=vtmax)\n",
    "    ucdb_city.plot(ax=axes, facecolor=\"none\", transform=lonlat, edgecolor=\"Green\")\n",
    "    axes.set_title(f'ºC')\n",
    "    axes.coastlines()\n",
    "    #for index, station in rval.iterrows():\n",
    "    #    station_lon = station['lon']\n",
    "    #    station_lat = station['lat']\n",
    "    #    \n",
    "    #    urban_mask_value = urban_mask.sel(lon=station_lon, lat=station_lat, method='nearest').item()\n",
    "    #    sea_mask_value = sftlf_mask.sel(lon=station_lon, lat=station_lat, method='nearest').item()\n",
    "    #    orog_mask_value=orog_mask.sel(lon=station_lon, lat=station_lat, method='nearest').item()\n",
    "    #    \n",
    "    #    if urban_mask_value > 0:\n",
    "    #        station_color = 'grey'  \n",
    "    #    elif sea_mask_value > 0 and orog_mask_value > 0:\n",
    "    #        station_color = 'black'\n",
    "    #    else:\n",
    "    #        station_color = 'none' \n",
    "    #                \n",
    "    #    axes[row, col].plot(station_lon, station_lat, marker='o', markersize=3, color=station_color)\n",
    "    \n",
    "    for i in range(len(rlon_values) ):\n",
    "        for j in range(len(rlat_values)):\n",
    "            if non_urban_mask[j, i].all()==True:\n",
    "                plot_boundary(axes, rlon_values[i], rlat_values[j], dist_rlon, dist_rlat,'blue',zorder=5,linewidth=4)\n",
    "            elif urban_mask[j, i].any() == True:\n",
    "                plot_boundary(axes, rlon_values[i], rlat_values[j], dist_rlon, dist_rlat,'red',zorder=50,linewidth=4)\n",
    "\n",
    "    # Time series plot\n",
    "    # Calculate monthly mean temperature within urban mask\n",
    "    time_urban = (ds['tasmin'].where(urban_mask).groupby('time.month').mean(dim=['time',select_name(rlat_names, ds_urban.coords),select_name(rlon_names, ds_urban.coords)]).compute())\n",
    "\n",
    "    # Calculate anomaly (difference from overall mean) for urban time series\n",
    "    time_plot_urban = time_urban - time_urban \n",
    "    \n",
    "    # Plot anomaly for urban time series with percentile\n",
    "    time_plot_urban.plot(ax=axes2, color='red', linewidth=3, linestyle='--',label='Mean of the urban cells')        \n",
    "    time_plot_urban_percentil = (ds['tasmin'].where(urban_mask).groupby('time.month').mean(dim=['time'])- time_urban)\n",
    "    lower_percentile_urban = np.nanpercentile(time_plot_urban_percentil, percentil, axis=[time_plot_urban_percentil.get_axis_num(select_name(rlat_names, ds_urban.coords)), time_plot_urban_percentil.get_axis_num(select_name(rlon_names, ds_urban.coords))])\n",
    "    upper_percentile_urban = np.nanpercentile(time_plot_urban_percentil, 100-percentil, axis=[time_plot_urban_percentil.get_axis_num(select_name(rlat_names, ds_urban.coords)), time_plot_urban_percentil.get_axis_num(select_name(rlon_names, ds_urban.coords))])\n",
    "    axes2.fill_between(time_plot_urban_percentil['month'], lower_percentile_urban, upper_percentile_urban, color='red', alpha=0.1)\n",
    "    axes2.fill_between(time_plot_urban_percentil['month'], time_plot_urban_percentil.min(dim=[select_name(rlat_names, ds_urban.coords),select_name(rlon_names, ds_urban.coords)]), time_plot_urban_percentil.max(dim=[select_name(rlat_names, ds_urban.coords),select_name(rlon_names, ds_urban.coords)]), color='red', alpha=0.1)\n",
    "\n",
    "    # Calculate monthly mean temperature for non-urban (rural) areas\n",
    "    time_rural = (ds['tasmin'].where(~urban_mask).where(non_urban_mask==1).groupby('time.month').mean(dim=['time',select_name(rlat_names, ds_urban.coords),select_name(rlon_names, ds_urban.coords)]).compute())\n",
    "    time_plot_rural = time_rural - time_urban\n",
    "\n",
    "     # Plot anomaly for rural time series with percentiles\n",
    "    time_plot_rural.plot(ax=axes2, color='blue', linewidth=3, linestyle='--', label='Mean of the not urban cells')        \n",
    "    time_plot_rural_percentil = (ds['tasmin'].where(~urban_mask).where(non_urban_mask==1).groupby('time.month').mean(dim=['time']) - time_urban)\n",
    "    lower_percentile_rural = np.nanpercentile(time_plot_rural_percentil, percentil, axis=[time_plot_rural_percentil.get_axis_num(select_name(rlat_names, ds_urban.coords)), time_plot_rural_percentil.get_axis_num(select_name(rlon_names, ds_urban.coords))])\n",
    "    upper_percentile_rural = np.nanpercentile(time_plot_rural_percentil, 100-percentil, axis=[time_plot_rural_percentil.get_axis_num(select_name(rlat_names, ds_urban.coords)), time_plot_rural_percentil.get_axis_num(select_name(rlon_names, ds_urban.coords))])\n",
    "    axes2.fill_between(time_plot_rural_percentil['month'], lower_percentile_rural, upper_percentile_rural, color='blue', alpha=0.1)\n",
    "    axes2.fill_between(time_plot_rural_percentil['month'], time_plot_rural_percentil.min(dim=[select_name(rlat_names, ds_urban.coords),select_name(rlon_names, ds_urban.coords)]), time_plot_rural_percentil.max(dim=[select_name(rlat_names, ds_urban.coords),select_name(rlon_names, ds_urban.coords)]), color='blue', alpha=0.1)\n",
    "    \n",
    "    #Calculate and plot anomaly for individual cells\n",
    "    for i in range(len(rlon_values)):\n",
    "        for j in range(len(rlat_values)):\n",
    "            if urban_mask[j, i].any():\n",
    "                if select_name(rlat_names, ds_urban.coords)=='y':\n",
    "                    time_plot_urban_loc = (ds['tasmin'].sel(x=rlon_values[i], y=rlat_values[j]).groupby('time.month').mean(dim=['time'])- time_urban)\n",
    "                else:\n",
    "                    time_plot_urban_loc = (ds['tasmin'].sel(rlon=rlon_values[i], rlat=rlat_values[j]).groupby('time.month').mean(dim=['time'])- time_urban)\n",
    "                time_plot_urban_loc.plot(ax=axes2, color='red', linewidth=0.5)\n",
    "            elif non_urban_mask[j, i].all()==1:\n",
    "                if select_name(rlat_names, ds_urban.coords)=='y':\n",
    "                    time_plot_rural_loc = (ds['tasmin'].sel(x=rlon_values[i], y=rlat_values[j]).groupby('time.month').mean(dim=['time'])- time_urban)\n",
    "                else:\n",
    "                    time_plot_rural_loc = (ds['tasmin'].sel(rlon=rlon_values[i], rlat=rlat_values[j]).groupby('time.month').mean(dim=['time'])- time_urban)\n",
    "\n",
    "                time_plot_rural_loc.plot(ax=axes2, color='blue', linewidth=0.5)\n",
    "    \n",
    "    # Define month names list\n",
    "    months_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December' ];\n",
    "    \n",
    "    # Add empty plot lines with labels for legend\n",
    "    axes2.plot([], color='red', linewidth=0.5, label='Urban Cells')\n",
    "    axes2.plot([], color='blue', linewidth=0.5, label='Not Urban Cells')\n",
    "    \n",
    "    # Set x-axis ticks and labels based on season\n",
    "    \n",
    "    axes2.set_xticks(range(1, 13))\n",
    "    axes2.set_xticklabels(months_names)\n",
    "    \n",
    "    \n",
    "    # Set axis labels, title and legend\n",
    "    axes2.set_xlabel('Months')\n",
    "    axes2.set_ylabel('Temperature Anomaly (°C)') \n",
    "    axes2.set_title('Monthly Temperature Anomalies (Urban vs. not Urban)')\n",
    "    axes2.legend()\n",
    "\n",
    "    return fig, fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321c3f7-f39d-405a-8431-cb35ff721f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ds,ds_sftlf, ds_orog, ds_urban, lat, lon, rval,res]=data_city(\"Athens\",location, \"REMO\",model_dict,\"CORDEX-CORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335c5a4-b965-4c15-9063-dc8203e5cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='EUR-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70726656-35ba-4852-815f-36896a6ee1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for files\n",
    "file_sea=glob.glob('/lustre/gmeteo/DATA/ESGF/REPLICA/DATA/cordex/output/'+domain+'/GERICS/ECMWF-ERAINT/evaluation/r0i0p0/REMO2015/v1/fx/sftlf/v'+'*'+'/sftlf_'+domain+'*')\n",
    "file_orog = glob.glob('/lustre/gmeteo/DATA/ESGF/REPLICA/DATA/cordex/output/'+domain+'/GERICS/ECMWF-ERAINT/evaluation/r0i0p0/REMO2015/v1/fx/orog/v'+'*'+'/orog_'+domain+'*')\n",
    "file_urban=glob.glob('/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/REMO/urbanfraction/orig_v3/'+domain+'*')\n",
    "\n",
    "sea_mask = xr.open_dataset(file_sea[0])\n",
    "urbanfraction=xr.open_dataset(file_urban[0])\n",
    "orography = xr.open_dataset(file_orog[0])\n",
    "\n",
    "res = int(orography.attrs['CORDEX_domain'].split('-')[1])\n",
    "\n",
    "ds_urban = urbanfraction['urban']\n",
    "ds_orog = orography['orog']\n",
    "ds_sftlf = sea_mask['sftlf'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240907f-d646-4475-acc7-436ba38a3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='/lustre/gmeteo/DATA/ESGF/REPLICA/DATA/cordex/output/'+domain+'/GERICS/ECMWF-ERAINT/evaluation/r1i1p1/REMO2015/v1/day/tasmin/v'\n",
    "file_names = [\n",
    "    'tasmin_'+domain+'_ECMWF-ERAINT_evaluation_r1i1p1_GERICS-REMO2015_v1_day_19790102-19801231.nc',\n",
    "    'tasmin_'+domain+'_ECMWF-ERAINT_evaluation_r1i1p1_GERICS-REMO2015_v1_day_19910101-19951231.nc',\n",
    "    'tasmin_'+domain+'_ECMWF-ERAINT_evaluation_r1i1p1_GERICS-REMO2015_v1_day_19960101-20001231.nc',\n",
    "]\n",
    "# Open each file individually and store them in a list\n",
    "individual_datasets = []\n",
    "for file_name in file_names:\n",
    "    file_path = glob.glob(directory+'*/'+file_name)\n",
    "    individual_datasets.append(xr.open_dataset(file_path[0]))\n",
    "\n",
    "# Combine the individual datasets into a single dataset\n",
    "ds = xr.concat(individual_datasets, dim='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738151d-6b63-420b-bcf0-cd41e9dd4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "[plot1,plot2]=plot_cities(ds, \"Athens\", \"REMO\", model_dict, ds_sftlf, ds_orog, ds_urban,\"CORDEX-CORE\", lat, lon, 1,1, -2, 2, rval,rlat_names,rlon_names, rotated_pole_names,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131123f2-8364-4fea-b1cb-5ac8e866b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Crear un nuevo archivo PDF\n",
    "with PdfPages(\"Athens-EUR-11-tasmin-RegCM-evaluation.pdf\") as pdf:\n",
    "    # Guardar el primer plot en el PDF\n",
    "    pdf.savefig(plot1)\n",
    "    # Guardar el segundo plot en el PDF\n",
    "    pdf.savefig(plot2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff22013-49af-4dfa-9bfc-5afd901ba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='/lustre/gmeteo/DATA/ESGF/REPLICA/DATA/cordex/output/EAS-22/ICTP/MOHC-HadGEM2-ES/historical/r1i1p1/RegCM4-4/v0/day/tasmin/v20190502'\n",
    "file_names = [\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19800101-19801230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19810101-19811230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19820101-19821230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19830101-19831230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19840101-19841230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19850101-19851230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19860101-19861230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19870101-19871230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19880101-19881230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19890101-19891230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19900101-19901230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19910101-19911230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19920101-19921230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19930101-19931230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19940101-19941230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19950101-19951230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19960101-19961230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19970101-19971230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19980101-19981230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_19990101-19991230.nc',\n",
    "    'tasmin_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_day_20000101-20001230.nc',\n",
    "]\n",
    "\n",
    "# Open each file individually and store them in a list\n",
    "individual_datasets = []\n",
    "for file_name in file_names:\n",
    "    file_path = glob.glob(directory+'/'+file_name)\n",
    "    individual_datasets.append(xr.open_dataset(file_path[0]))\n",
    "\n",
    "# Combine the individual datasets into a single dataset\n",
    "ds = xr.concat(individual_datasets, dim='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bad2fd-5f04-462a-a42e-191f7df77f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for files\n",
    "directory_orog ='/lustre/gmeteo/DATA/ESGF/REPLICA/DATA/cordex/output/EAS-22/ICTP/MOHC-HadGEM2-ES/historical/r1i1p1/RegCM4-4/v0/fx/orog/v20190502/orog_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_fx.nc'\n",
    "directory_sea = '/lustre/gmeteo/DATA/ESGF/REPLICA/DATA/cordex/output/EAS-22/ICTP/MOHC-HadGEM2-ES/historical/r1i1p1/RegCM4-4/v0/fx/sftlf/v20190502/sftlf_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_ICTP-RegCM4-4_v0_fx.nc'\n",
    "directory_urban='/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/RegCM/urbanfraction/EAS-22.nc'\n",
    "sea_mask = xr.open_dataset(directory_sea)\n",
    "urbanfraction=xr.open_dataset(directory_urban)\n",
    "orography = xr.open_dataset(directory_orog)\n",
    "\n",
    "res = int(orography.attrs['CORDEX_domain'].split('-')[1])\n",
    "\n",
    "                 \n",
    "ds_urban = urbanfraction['sftuf']\n",
    "ds_orog = orography['orog']\n",
    "ds_sftlf = sea_mask['sftlf'] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambaforge",
   "language": "python",
   "name": "conda-env-mambaforge-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
